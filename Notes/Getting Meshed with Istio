Getting Meshed with Istio

Installing Istio

-  In order to get started with Istio we first actually need an environment to run Istio inside of. And while you can run Istio in a general VM-based environment it's most commonly deployed in conjunction with Kubernetes. So in our module directory here we have an install description file, and we're going to just walk through that real quick. We're going to look at this file in order to look at the different tools that you can install and some options for those installation processes. In order to talk to Kubernetes we do have to have the kubectl command. And so the process for doing that is well documented on the Kubernetes site, and here's a link to get to that particular installation. In addition I find the simplest way to get a Kubernetes environment running if you don't have access to one in a public cloud or maybe in your business environment where you might have a private Kubernetes environment, I find minikube to be a pretty effective way of getting Kubernetes running, and we can go ahead and install that from the minikube install instructions, basically it's another application binary that can be installed. But there are some requirements around hypervisors that you need to be aware of. And we're also going to need another tool to interact with Kubernetes and that is the helm tool. I find helm to be one of the easiest ways to install a distributed application like Istio, and helm will help us do that. So we'll also want to go ahead and install the helm resources that are described in this page. And then of course, we need Istio. So we're going to want to go ahead and grab Istio. And like most applications in this particular space, this cloud native space, Istio is changing pretty rapidly. But at the time of this recording we're using the 1.0.2 release, which you can actually grab from this link, which is the tagged release, and so you can actually follow along with this exact version of the Istio packages. You're going to want to go ahead and grab those packages, and they are specific to your operating system. So in this case we're on an OSX machine. So I'm going to grab the Istio package from the OSX download. You'll get the specific versions for Windows or Linux based environments at the release link here. You can also create a directory. I created a class directory to work from within just to make it easier to remember how to get back to the Istio directory if we need to and extracted the resources into that directory for our use. Now once we actually get Istio installed, installed being extracted really, we need to actually install the application into our Kubernetes environment. So once the Kubernetes system is up and running, or we have access to our Kubernetes system, we can do kubectl get nodes for example. We can then go ahead and install the helm components that we need and use helm to then install our Istio environment. For the helm part there is a roles-based access requirement so if you haven't already established helm with the right roles-based access there is an included helm manifest, well actually Kubernetes manifest, to create that roles-based access. You can install that with this kubectl apply command. There is also then the need to initialize helm, and if you followed the normal helm install instructions you will already have initialized your helm, but this upgrade will make sure that you're using the latest version of the tiller service account for that helm environment. And then lastly, we're actually going to use helm to install Istio. And we're going to do that by, a, creating a namespace for Istio to sit in and also enabling two key resources. We want to make sure that we don't have the mutual tls service enabled. We're going to do that in a different fashion. We do want to make sure that we have our tracing capability enabled. So those two sets are default. I also have two other sets for the istio-ingressgateway and the istio-egressgateway. And those are specific to the fact that I'm deploying and using minikube which does not have a load balancer type of gateway capability. You could describe that here or you could actually rather remove these two lines if you happen to be in a cloud environment or maybe your office has an environment that has a load balancer capable Kubernetes environment. You can then remove these two resources and the system will continue to operate properly. So once we run this helm install, which we'll do in just a second, we'll actually have the Istio environment running. And that's principally the pilot, which is the central controller for Istio, and instead of monitoring and metering management services including Mixer, Prometheus, and the Jaeger environment. We can also check that it's actually running by just getting the pods within the Istio system. So I'm going to grab the helm chart creation process and make sure that we have all these resources. And then I'm going to do the CD that was suggested earlier in here so there's a change directory into the Istio directory. So we're going to do that first, ~/Class/istio, cause that's where I put the Istio commands and components and now I can just do a command v to paste the resources. We're going to do this install without doing an upgrade. So I'm just going to modify this command. And now it'll actually properly install the system. So the installation actually happens pretty quickly, but the system isn't yet running. If we do kubectl get pods -n for namespace and we created the istio-system namespace as a par of the helm installation we can see that the containers are starting to create. Now this will take another couple of minutes and we can either watch this output or we can just rerun the same kubectl command in order to see the output change, and we should eventually have all of the containers running.

Injecting Istio into a microservice

- Now that we have an Istio environment running, we'd actually like to make use of that environment, so we want to launch a service to actually connect via Istio. In order to do that, we actually need to launch a service. So in our module directory here, if we do an ls so we can get the directory structure, and we see that we have an instruction, document, and a yaml manifest. The yaml manifest is a Kubernetes manifest that we're going to use to actually create our application. If we do more on the install tab, install simple app.md file, you can see we have a set of instructions here. I'm going to focus in on the actual instructions themselves. But just, we're going to launch simple Nginx based application, and all that this does is it launches an internal script when it gets created. The application will deliver some http endpoints that will give us host name and version information about the deployed container. So it's a very simple little application. So I'm going to grab this set of commands and we're going to use these commands to first off, create our deployment and pod. These are Kubernetes constructs that define the host name application. We're going to sleep for 10 seconds to allow the system to catch up and actually get a chance to launch that application. And then we're going to use the kubectrl get command to discover the particular pod that got created by the host name manifest. Once the system is up and running, we can also query the minikube service to get its node port, and we'll then use the node port service that also gets created by that host name yaml manifest to query the application and get some basic information about the app itself. Once we've done that, we'll find that we are just still talking directly to the service. We don't have Istio involved. We can see that because we can see the number of containers that are embedded inside of our application. We'll then go and inject manually the Kubernetes additional manifest information from Istio in order to create the Istio connection. Then you can see that we'll first look at that command information, and then we'll actually inject it directly into the file itself. Going to grab these particular commands. Command+C to copy them. And then Command+V should paste them. Alright, so, now we've done our first kubectrl command, which creates this host name resource, and you can see that it's both a deployment and a service that get created. We also then slept for 10 seconds. That's just long enough for the system to download the container. And then we go and query the environment to say, hey, is our pod up and running? We can see that the host name pod is running. There's one container, and it is ready. This is the ready state, and this is saying that there's one container available and they're running. That's great, but that's still not actually communicating with Istio because we only have the one container running. So what we can do is we can actually delete this. So we're going to do kubectrl delete -f hostname.yaml, and then we're going to recreate this environment, but we're going to inject the Istio control components. We're going to use the Istio control tool to do that. So we're going to use the Istio control command with its use kube inject capability, which will create the additional embedded container needed for the resource, and then we're just going to automatically apply it, so we don't actually have to turn it into a file and then apply that file. So we're going to want to copy this command, and I'm going to paste this and go ahead and run it. So that's now been created. If we rerun our get command, going to do a copy and a paste on that, and now we see that the host name app is running, and instead of one container, we have two, and one of those is the Istio proxy and the other is our application. If we do a curl at this point, we will still get the exact same result because the Istio proxy, while it's running, hasn't actually been configured to do anything. Interesting. Do that again. Grab the curl, copy it, and paste it. That looks a little bit better. And you can see we can still talk to the application.